{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, os\n",
    "from PyPDF2 import PdFReader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cadential.yaml\") as f:\n",
    "    cadential = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatOpenAI{\n",
    "    openai_api_key=cadential[\"OPENAI_API_KEY\"],\n",
    "    model =\"gpt-3.5-turbo\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings= HuggingFaceBgeEmbeddings(\n",
    "    model_name= 'BAAI/bge-small-en-v1.5',\n",
    "    model_kwargs ={ 'device':'cpu' },\n",
    "    encode_kwargs={'normalize_kwargs':False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_pdf_text(pdf_dir):\n",
    "       pdf_docs=[os.path.join(pdf_dir,pdf) for pdf in os.listdir(pdf_dir)]\n",
    "       text=\"\"\n",
    "       for pdf in pdf_docs:\n",
    "           pdf_reader=PdfReader(pdf)\n",
    "           for page in pdf_reader.pages:\n",
    "               text+=page.extract_text()\n",
    "        return\n",
    " def chunk_text(text):\n",
    "    text_splitter=CharacterTextSplitter(\n",
    "        seperator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overLap=200\n",
    "\n",
    "    )\n",
    "    chunk=text_splitter.split_text(text)\n",
    "    return chunks\n",
    " \n",
    " def vector_store(chuks):\n",
    "    vectStore=FAISS.from_texts(\n",
    "        texts=\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
